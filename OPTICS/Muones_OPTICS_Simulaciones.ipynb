{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv-bxRtUnECK"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import OPTICS\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSgcmD2GyDh3"
      },
      "outputs": [],
      "source": [
        "def iter_json(text: str):\n",
        "    \"\"\"\n",
        "    Intenta cargar el JSON completo, incluso si está todo en una línea.\n",
        "    Si falla, busca bloques 'Event_*' dentro del texto.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        obj = json.loads(text)\n",
        "        if isinstance(obj, dict):\n",
        "            yield obj\n",
        "            return\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Si llega aquí, el JSON completo no se pudo parsear.\n",
        "    # Extraemos los sub-bloques \"Event_x\" usando regex:\n",
        "    pattern = r'\"Event_\\d+\"\\s*:\\s*\\{.*?\\}(?=,\"Event_\\d+\"|}})'\n",
        "    matches = re.findall(pattern, text)\n",
        "    if matches:\n",
        "        # reconstruimos un objeto \"Output\"\n",
        "        yield {\"Output\": json.loads(\"{\" + \",\".join(matches) + \"}\")}\n",
        "\n",
        "def get_in(d, keys, default=None):\n",
        "    cur = d\n",
        "    for k in keys:\n",
        "        if isinstance(cur, dict) and k in cur:\n",
        "            cur = cur[k]\n",
        "        else:\n",
        "            return default\n",
        "    return cur\n",
        "\n",
        "def events_to_dataframe_2(text: str):\n",
        "    \"\"\"Convierte el contenido JSON de los eventos en un DataFrame con todas las columnas disponibles.\"\"\"\n",
        "    records = []\n",
        "\n",
        "    for rec in iter_json(text):\n",
        "        out = rec.get(\"Output\", {})\n",
        "        for evname, ev in out.items():\n",
        "            flux = ev.get(\"InputFlux\", {})\n",
        "            det = ev.get(\"Detector_0\", {})\n",
        "            opt = det.get(\"OptDevice_0\", {})\n",
        "\n",
        "            row = {\n",
        "                \"Event\": evname,\n",
        "                \"ID\": flux.get(\"ID\"),\n",
        "                \"Position_x\": flux.get(\"Position\", [None]*3)[0],\n",
        "                \"Position_y\": flux.get(\"Position\", [None]*3)[1],\n",
        "                \"Position_z\": flux.get(\"Position\", [None]*3)[2],\n",
        "                \"Momentum_x\": flux.get(\"Momentum\", [None]*3)[0],\n",
        "                \"Momentum_y\": flux.get(\"Momentum\", [None]*3)[1],\n",
        "                \"Momentum_z\": flux.get(\"Momentum\", [None]*3)[2],\n",
        "            }\n",
        "\n",
        "            # Agregar campos directos de Detector_0\n",
        "            for k, v in det.items():\n",
        "                if k != \"OptDevice_0\" and not isinstance(v, dict):\n",
        "                    row[k] = v\n",
        "\n",
        "            # Agregar todas las categorías dentro de OptDevice_0\n",
        "            for k, v in opt.items():\n",
        "                if isinstance(v, list):\n",
        "                    row[k] = v  # guardamos la lista completa\n",
        "                else:\n",
        "                    row[k] = v\n",
        "\n",
        "            records.append(row)\n",
        "\n",
        "    return pd.DataFrame(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYEANLMfy3Wt"
      },
      "outputs": [],
      "source": [
        "def Charge_Histogram_All(df,df_2, df_3,cluster_col='Cluster', bin_width=7):\n",
        "#def Charge_Histogram_All(df,cluster_col='Cluster',bin_width=7):\n",
        "    \"\"\"\n",
        "    Generates an histogram from the column 'Charge':\n",
        "    - Global all data\n",
        "    - Splits the data according to each cluster.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame with the column 'Charge' could be cluster_col (ej: 0,1,2)\n",
        "    - cluster_col: name of the cluster\n",
        "    - bin_width: the width of the bins\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # --- bins compartidos para todos ---\n",
        "\n",
        "    min_val, max_val = df['Charge'].min(), df['Charge'].max()\n",
        "    bins = np.arange(min_val, max_val + bin_width, bin_width)\n",
        "\n",
        "    # --- histograma global ---\n",
        "    counts, bin_edges = np.histogram(df['Charge'], bins=bins)\n",
        "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "    plt.semilogy(bin_centers, counts, color='red', lw=3,alpha=0.6,label=\"Total\", zorder=5)\n",
        "\n",
        "    counts_2, bin_edges_2 = np.histogram(df_2['Charge'], bins=bins)\n",
        "    bin_centers_2 = (bin_edges_2[:-1] + bin_edges_2[1:]) / 2\n",
        "    plt.semilogy(bin_centers_2, counts_2, color='black', lw=3,alpha=0.8,linestyle='--',label=\"Muons\", zorder=5)\n",
        "\n",
        "    counts_3, bin_edges_3 = np.histogram(df_3['Charge'], bins=bins)\n",
        "    bin_centers_3 = (bin_edges_3[:-1] + bin_edges_3[1:]) / 2\n",
        "    plt.semilogy(bin_centers_3, counts_3, color='#BF00BF', lw=3,alpha=0.8,linestyle='--', label=\"Electrons\", zorder=5)\n",
        "\n",
        "    # --- histogramas por cluster ---\n",
        "    clusters = sorted(df[cluster_col].unique())\n",
        "    for c in clusters:\n",
        "        subset = df[df[cluster_col] == c]['Charge'].to_numpy()\n",
        "        counts, bin_edges = np.histogram(subset, bins=bins)\n",
        "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "        plt.semilogy(bin_centers, counts, label=f\"Cluster {c}\", alpha=0.9, zorder=4)\n",
        "\n",
        "    plt.ylabel(\"Number of Counts\", fontsize=20)\n",
        "    plt.xlabel(\"ADC\", fontsize=20)\n",
        "    #plt.title(\"Charge Histogram\", fontsize=20)\n",
        "    plt.grid(True)\n",
        "    plt.legend(fontsize='20')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analizar_evento(tiempos_pe):\n",
        "    \"\"\"\n",
        "    Analiza un evento a partir de los tiempos de llegada de los fotoelectrones.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    tiempos_pe : list o array\n",
        "        Tiempos de llegada de los fotoelectrones (en segundos).\n",
        "    bins : int\n",
        "        Número de bins para el histograma.\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    dict con:\n",
        "        - 'Total_PEs_Deposited': Total de PEs del evento\n",
        "        - 'Pico': Máximo número de PEs en un bin\n",
        "        - 'Tiempo_90': Tiempo que tarda en depositar el 90% de los PEs (ns)\n",
        "        - 'Duration': Duración del pulso (ns)\n",
        "        - 'bin_centers': Centros de bins (ns)\n",
        "        - 'counts': Número de PEs por bin\n",
        "    \"\"\"\n",
        "\n",
        "    # Convertir tiempos a ns\n",
        "    tiempos_ns = np.array(tiempos_pe) * 1e9\n",
        "\n",
        "    # Mantener 8 ns siempre\n",
        "    # Asegurarse de que `bins` sea al menos 1 para evitar errores con np.histogram\n",
        "    time_range = tiempos_ns.max() - tiempos_ns.min()\n",
        "    bins = int(time_range/8)\n",
        "    if bins <= 0:\n",
        "      print(bins)\n",
        "      bins = 1\n",
        "\n",
        "    # Histograma\n",
        "    counts, bin_edges = np.histogram(tiempos_ns, bins=bins)\n",
        "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
        "\n",
        "    # Total de PEs\n",
        "    Total_PEs_Deposited = counts.sum()\n",
        "\n",
        "    # Pico del pulso\n",
        "    Pico = counts.max()\n",
        "\n",
        "    # DataFrame para la acumulada\n",
        "    df = pd.DataFrame({\n",
        "        'tiempos': bin_centers,\n",
        "        'Num_fotoelectrones': counts\n",
        "    })\n",
        "    df['frecuencia_acumulada'] = df['Num_fotoelectrones'].cumsum()\n",
        "\n",
        "    # Tiempo para depositar 90% de la señal\n",
        "    # Si hay un solo bin, o pocos datos, puede que el 90% sea el primer bin center\n",
        "    if not df.empty and Total_PEs_Deposited > 0:\n",
        "        tiempo_90_signal = df[df['frecuencia_acumulada'] >= Total_PEs_Deposited*0.9]['tiempos'].iloc[0]\n",
        "    else:\n",
        "        tiempo_90_signal = None # O un valor por defecto si no hay PEs o datos\n",
        "\n",
        "    # Duración del pulso\n",
        "    if len(bin_centers) > 1:\n",
        "        duration = bin_centers.max() - bin_centers.min()\n",
        "    elif len(bin_centers) == 1:\n",
        "        duration = 0.0 # O el ancho del bin si se considera relevante\n",
        "    else:\n",
        "        duration = None\n",
        "\n",
        "    return {\n",
        "        'Total_PEs_Deposited': Total_PEs_Deposited,\n",
        "        'Pico': Pico,\n",
        "        'Tiempo_90': tiempo_90_signal,\n",
        "        'Duration': duration,\n",
        "        'bin_centers': bin_centers,\n",
        "        'counts': counts\n",
        "    }"
      ],
      "metadata": {
        "id": "zJuTa0T6fYv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Add_Time_Features(df, column='PETimeDistribution'):\n",
        "    \"\"\"\n",
        "    Añade al DataFrame las características temporales de cada evento.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame con la columna de tiempos de PEs por evento.\n",
        "    column : str\n",
        "        Nombre de la columna con los tiempos de PEs.\n",
        "    bins : int\n",
        "        Número de bins para el histograma.\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame con columnas adicionales:\n",
        "        - 'Total_PEs_Deposited'\n",
        "        - 'Time_90_PEs_Deposited'\n",
        "        - 'Pulse_Duration'\n",
        "    \"\"\"\n",
        "\n",
        "    all_Total_PEs = []\n",
        "    all_Peak = []\n",
        "    all_Time_90 = []\n",
        "    all_Duration = []\n",
        "\n",
        "    for i in range(len(df[column])):\n",
        "        tiempos_pe = df[column][i]\n",
        "        resultado = analizar_evento(tiempos_pe)\n",
        "        all_Total_PEs.append(resultado['Total_PEs_Deposited'])\n",
        "        all_Peak.append(resultado['Pico'])\n",
        "        all_Time_90.append(resultado['Tiempo_90'])\n",
        "        all_Duration.append(resultado['Duration'])\n",
        "\n",
        "    df['Total_PEs_Deposited'] = all_Total_PEs\n",
        "    df['Pico'] = all_Peak\n",
        "    df['Time_90_PEs_Deposited'] = all_Time_90\n",
        "    df['Pulse_Duration'] = all_Duration\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "koKJDp-kEqsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def particles(df,ID):\n",
        "  df_particles = df[(df['ID'] == ID[0]) | (df['ID'] == ID[1])]\n",
        "  df_particles = df_particles[df_particles['PETimeDistribution'].astype(bool) & df_particles['PETimeDistribution'].apply(lambda arr: len(arr) > 9)]\n",
        "  df_particles = df_particles[['Event','ID','Position_x','Position_y','Position_z','Momentum_x','Momentum_y','Momentum_z','EnergyDeposit','Charge','PETimeDistribution']]\n",
        "  df_particles.reset_index(drop=True, inplace=True)\n",
        "  return df_particles"
      ],
      "metadata": {
        "id": "2SO1AO7FuKxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gzip.open('/content/drive/MyDrive/Rayos Cósmicos/Meiga/chiapas_parte_1.2.json.gz', 'rt', encoding='utf-8') as f:\n",
        "  text = f.read()\n",
        "df_Chiapas = events_to_dataframe_2(text)"
      ],
      "metadata": {
        "id": "t3eF9NXVOFVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time has chaged to nanoseconds\n",
        "ID = [13,-13]\n",
        "df_Chiapas_muones = particles(df_Chiapas,ID)\n",
        "ID = [11,-11]\n",
        "df_Chiapas_electrones = particles(df_Chiapas,ID)"
      ],
      "metadata": {
        "id": "d6W2zuGrvOyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Add_Time_Features(df_Chiapas_muones)"
      ],
      "metadata": {
        "id": "oPSGPgC_4pG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_muons_process =  df_Chiapas_muones[['ID','Total_PEs_Deposited','Pico','Time_90_PEs_Deposited','Pulse_Duration','Charge']]\n",
        "df_electrones_process =  df_Chiapas_electrones[['ID','Total_PEs_Deposited','Pico','Time_90_PEs_Deposited','Pulse_Duration','Charge']]"
      ],
      "metadata": {
        "id": "SeATZFA_BQQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.concat([df_muons_process,df_electrones_process])"
      ],
      "metadata": {
        "id": "qVyVSQQ0RvN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mezclado = df_all.sample(frac=0.5).reset_index(drop=True)\n",
        "df_mezclado['ID'] = abs(df_mezclado['ID'])\n",
        "#df_test = df_mezclado.head(100000)\n",
        "#df_test = df_mezclado"
      ],
      "metadata": {
        "id": "mLFpwsigUsMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mezclado"
      ],
      "metadata": {
        "id": "kQBC1ZSZiBjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OPTICS para las simulaciones:\n",
        "El primer paso consiste en utilizar PCA. Esto reduce las dimensiones a dos."
      ],
      "metadata": {
        "id": "QQqP2owQK-KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_clean = df_test.copy()\n",
        "#features_clean = df_clean[['Total_PEs_Deposited','Pico','Time_90_PEs_Deposited','Pulse_Duration']]"
      ],
      "metadata": {
        "id": "qhGKVHVPW5Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "features = df_test[['Total_PEs_Deposited','Pico','Time_90_PEs_Deposited','Pulse_Duration']]\n",
        "\n",
        "# Z-score absoluto\n",
        "Z = np.abs(zscore(features))\n",
        "\n",
        "# Máscara: fila es outlier si alguna columna tiene Z > 3\n",
        "outlier_mask = (Z >2).any(axis=1)\n",
        "\n",
        "# DataFrame limpio\n",
        "df_clean = df_test[~outlier_mask].reset_index(drop=True)\n",
        "\n",
        "# Porcentaje de filas eliminadas\n",
        "porcentaje_perdida = 100 * outlier_mask.sum() / len(df_test)\n",
        "print(f\"Porcentaje de pérdida por outliers: {porcentaje_perdida:.2f}%\")"
      ],
      "metadata": {
        "id": "SQ_vHS3kj6qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Promedio num PE:',df_clean['Total_PEs_Deposited'].mean())\n",
        "print('Promedio Pico:',df_clean['Pico'].mean())\n",
        "print('Promedio Tiempo_90:',df_clean['Time_90_PEs_Deposited'].mean())\n",
        "print('Promedio Duracion_pulso:',df_clean['Pulse_Duration'].mean())"
      ],
      "metadata": {
        "id": "KFS6giFOX7oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df_clean[['Total_PEs_Deposited','Pico','Time_90_PEs_Deposited','Pulse_Duration']]"
      ],
      "metadata": {
        "id": "YIIRMdXzEQGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalado y PCA\n",
        "X_scaled = StandardScaler().fit_transform(df_clean)\n",
        "pca = PCA(n_components=3)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# IDs de partículas\n",
        "#particles_ID = df_clean['ID']\n",
        "\n",
        "# Colores según ID\n",
        "#cmap = plt.cm.Dark2\n",
        "#norm = plt.Normalize(vmin=min(particles_ID), vmax=max(particles_ID))\n",
        "\n",
        "# Leyenda personalizada\n",
        "#id_labels = {11: 'Electrons (ID=11)', 13: 'Muons (ID=13)'}\n",
        "#unique_ids = np.unique(particles_ID)\n",
        "#handles = [plt.Line2D([0], [0], marker='o', color='w',\n",
        "#                      markerfacecolor=cmap(norm(uid)),\n",
        "#                     markersize=8, label=id_labels.get(uid, f'ID {uid}'))\n",
        "#           for uid in unique_ids]\n",
        "\n",
        "# Gráficos\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# PCA1 vs PCA2\n",
        "axes[0].scatter(X_pca[:, 0], X_pca[:, 1], s=20, alpha=0.6)\n",
        "axes[0].set_xlabel(\"PCA1\")\n",
        "axes[0].set_ylabel(\"PCA2\")\n",
        "#axes[0].set_title(\"Proyección PCA1 vs PCA2\")\n",
        "\n",
        "# PCA1 vs PCA3\n",
        "axes[1].scatter(X_pca[:, 0], X_pca[:, 2], s=20, alpha=0.6)\n",
        "axes[1].set_xlabel(\"PCA1\")\n",
        "axes[1].set_ylabel(\"PCA3\")\n",
        "#axes[1].set_title(\"PCA1 vs PCA3\")\n",
        "\n",
        "# PCA2 vs PCA3\n",
        "axes[2].scatter(X_pca[:, 1], X_pca[:, 2], s=20, alpha=0.6)\n",
        "axes[2].set_xlabel(\"PCA2\")\n",
        "axes[2].set_ylabel(\"PCA3\")\n",
        "#axes[2].set_title(\"Proyección PCA2 vs PCA3\")\n",
        "\n",
        "# Leyenda y diseño\n",
        "#fig.legend(handles=handles, title=\"Particle\", loc=\"upper right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "oEAapOT8SVXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import OPTICS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "optics = OPTICS(min_samples=2000, xi=0.1, max_eps=2, min_cluster_size=5000)\n",
        "labels = optics.fit_predict(X_pca)\n",
        "\n",
        "# --- Configuración de color ---\n",
        "unique_labels = np.unique(labels)\n",
        "cmap = plt.cm.tab10\n",
        "norm = plt.Normalize(vmin=min(unique_labels), vmax=max(unique_labels))\n",
        "\n",
        "# --- Figura con tres proyecciones ---\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# PCA1 vs PCA2\n",
        "axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=cmap, s=10, alpha=0.6)\n",
        "axes[0].set_xlabel(\"PCA1\")\n",
        "axes[0].set_ylabel(\"PCA2\")\n",
        "axes[0].set_title(\"OPTICS: PCA1 vs PCA2\")\n",
        "\n",
        "# PCA1 vs PCA3\n",
        "axes[1].scatter(X_pca[:, 0], X_pca[:, 2], c=labels, cmap=cmap, s=10, alpha=0.6)\n",
        "axes[1].set_xlabel(\"PCA1\")\n",
        "axes[1].set_ylabel(\"PCA3\")\n",
        "axes[1].set_title(\"OPTICS: PCA1 vs PCA3\")\n",
        "\n",
        "# PCA2 vs PCA3\n",
        "axes[2].scatter(X_pca[:, 1], X_pca[:, 2], c=labels, cmap=cmap, s=10, alpha=0.6)\n",
        "axes[2].set_xlabel(\"PCA2\")\n",
        "axes[2].set_ylabel(\"PCA3\")\n",
        "axes[2].set_title(\"OPTICS: PCA2 vs PCA3\")\n",
        "\n",
        "# --- Leyenda automática ---\n",
        "handles, legend_labels = axes[0].get_legend_handles_labels()\n",
        "legend1 = fig.legend(*axes[0].collections[0].legend_elements(),\n",
        "                     title=\"Clusters\", loc=\"upper right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qN8yu3WoNWzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_series = pd.Series(labels)\n",
        "labels_series.value_counts()"
      ],
      "metadata": {
        "id": "Xj5YMC-hNosF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean['Clusters'] = labels"
      ],
      "metadata": {
        "id": "TrdIicJSbP5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_electrones = df_clean[(df_clean['ID'] == 11) | (df_clean['ID'] == -11)]"
      ],
      "metadata": {
        "id": "cYQA9erlcqBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_muones = df_clean[(df_clean['ID'] == 13) | (df_clean['ID'] == -13)]"
      ],
      "metadata": {
        "id": "sJPbfj8LdGqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_electrones)"
      ],
      "metadata": {
        "id": "5ynIJ5QzfxET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reach = optics.reachability_[optics.ordering_]\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(reach)\n",
        "plt.title(\"Reachability Plot (OPTICS)\")\n",
        "plt.xlabel(\"Sample index (ordered)\")\n",
        "plt.ylabel(\"Reachability distance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gfuY3KcTN3Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Charge_Histogram_All(df_clean,cluster_col='Clusters',bin_width=7)\n",
        "Charge_Histogram_All(df_clean,df_muones,df_electrones,cluster_col='Clusters',bin_width=2)"
      ],
      "metadata": {
        "id": "Ry6hdQsJcXx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_muones['Clusters'].value_counts()"
      ],
      "metadata": {
        "id": "h2e0SED1pU33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(len(df_muones)-52636)*100/len(df_muones)"
      ],
      "metadata": {
        "id": "vsj0w37Mpym6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_electrones['Clusters'].value_counts()"
      ],
      "metadata": {
        "id": "5_ETKVc5rukJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(len(df_electrones)-15290)*100/len(df_electrones)"
      ],
      "metadata": {
        "id": "m2IBpTBDrzWa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}